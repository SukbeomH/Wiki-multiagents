# ë°°í¬ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

AI Knowledge Graph Systemì˜ ë°°í¬ ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ë¡œì»¬ ê°œë°œ í™˜ê²½ë¶€í„° í”„ë¡œë•ì…˜ ë°°í¬ê¹Œì§€ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œì˜ ë°°í¬ ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

## ğŸ—ï¸ ë°°í¬ ì•„í‚¤í…ì²˜

### ì „ì²´ êµ¬ì„±ë„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Load Balancer â”‚    â”‚   FastAPI       â”‚    â”‚   Streamlit     â”‚
â”‚   (Nginx)       â”‚â”€â”€â”€â”€â”‚   Backend       â”‚â”€â”€â”€â”€â”‚   Frontend      â”‚
â”‚   Port 80/443   â”‚    â”‚   Port 8000     â”‚    â”‚   Port 8501     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   Storage       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚   Layer         â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                             â”‚                             â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚   Cache  â”‚              â”‚   Vector    â”‚              â”‚   Knowledgeâ”‚
â”‚   (Disk) â”‚              â”‚   Store     â”‚              â”‚   Graph    â”‚
â”‚   ./data â”‚              â”‚   (FAISS)   â”‚              â”‚   (RDFLib) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ³ Docker ë°°í¬ (ê¶Œì¥)

### 1. ë¡œì»¬ Docker ë°°í¬

#### ê¸°ë³¸ ë°°í¬
```bash
# 1. ë¦¬í¬ì§€í† ë¦¬ í´ë¡ 
git clone <repository-url>
cd aibootcamp-final

# 2. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cp config/environment.template .env
# .env íŒŒì¼ í¸ì§‘

# 3. Docker Composeë¡œ ë°°í¬
docker-compose up -d

# 4. ì„œë¹„ìŠ¤ í™•ì¸
docker-compose ps
```

#### ê°œë°œ í™˜ê²½ ë°°í¬
```bash
# ê°œë°œ ë„êµ¬ í¬í•¨ ë°°í¬
docker-compose --profile dev up -d

# ì¶”ê°€ ì„œë¹„ìŠ¤:
# - Redis Commander (í¬íŠ¸ 8081)
# - Neo4j Browser (í¬íŠ¸ 7474)
# - Grafana (í¬íŠ¸ 3000)
```

### 2. í”„ë¡œë•ì…˜ Docker ë°°í¬

#### í”„ë¡œë•ì…˜ ì„¤ì •
```bash
# í”„ë¡œë•ì…˜ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export NODE_ENV=production
export DEBUG=false
export LOG_LEVEL=WARNING

# í”„ë¡œë•ì…˜ ë°°í¬
docker-compose -f docker-compose.prod.yml up -d
```

#### í”„ë¡œë•ì…˜ Docker Compose ì˜ˆì‹œ
```yaml
version: '3.8'

services:
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - fastapi
      - streamlit

  fastapi:
    build: 
      context: ./server
      dockerfile: Dockerfile.prod
    environment:
      - NODE_ENV=production
      - LOG_LEVEL=WARNING
    volumes:
      - ./data:/app/data
    restart: unless-stopped

  streamlit:
    build:
      context: ./app
      dockerfile: Dockerfile.prod
    environment:
      - NODE_ENV=production
    restart: unless-stopped
```

## â˜ï¸ í´ë¼ìš°ë“œ ë°°í¬

### 1. AWS ë°°í¬ (Terraform)

#### ì¸í”„ë¼ ë°°í¬
```bash
# 1. AWS ì¸ì¦ ì„¤ì •
aws configure

# 2. Terraform ì´ˆê¸°í™”
cd infra/terraform
terraform init

# 3. ì¸í”„ë¼ ë°°í¬
terraform plan
terraform apply

# 4. ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬
cd ../scripts
./deploy.sh
```

#### Terraform êµ¬ì„± ìš”ì†Œ
- **EC2 Instance**: t3.large (2 vCPU, 8GB RAM)
- **VPC**: í”„ë¼ì´ë¹—/í¼ë¸”ë¦­ ì„œë¸Œë„·
- **Security Groups**: í¬íŠ¸ 22, 80, 443, 8000, 8501
- **EBS Volume**: 50GB ë°ì´í„° ì €ì¥ìš©
- **Elastic IP**: ê³ ì • ê³µì¸ IP

### 2. Google Cloud Platform ë°°í¬

#### GKE (Kubernetes) ë°°í¬
```bash
# 1. GKE í´ëŸ¬ìŠ¤í„° ìƒì„±
gcloud container clusters create ai-kg-cluster \
  --zone=us-central1-a \
  --num-nodes=3 \
  --machine-type=e2-standard-2

# 2. kubectl ì„¤ì •
gcloud container clusters get-credentials ai-kg-cluster --zone=us-central1-a

# 3. Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë°°í¬
kubectl apply -f k8s/
```

#### Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì˜ˆì‹œ
```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-kg-backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ai-kg-backend
  template:
    metadata:
      labels:
        app: ai-kg-backend
    spec:
      containers:
      - name: fastapi
        image: ai-kg-backend:latest
        ports:
        - containerPort: 8000
        env:
        - name: AZURE_OPENAI_ENDPOINT
          valueFrom:
            secretKeyRef:
              name: azure-secrets
              key: endpoint
```

### 3. Azure ë°°í¬

#### Azure Container Instances
```bash
# 1. Azure CLI ë¡œê·¸ì¸
az login

# 2. ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ ìƒì„±
az group create --name ai-kg-rg --location eastus

# 3. ì»¨í…Œì´ë„ˆ ì¸ìŠ¤í„´ìŠ¤ ë°°í¬
az container create \
  --resource-group ai-kg-rg \
  --name ai-kg-backend \
  --image ai-kg-backend:latest \
  --ports 8000 \
  --environment-variables \
    AZURE_OPENAI_ENDPOINT=$AZURE_OPENAI_ENDPOINT \
    AZURE_OPENAI_API_KEY=$AZURE_OPENAI_API_KEY
```

## ğŸ”§ í™˜ê²½ë³„ ì„¤ì •

### 1. ê°œë°œ í™˜ê²½

#### í™˜ê²½ë³€ìˆ˜
```bash
# .env.development
DEBUG=true
LOG_LEVEL=DEBUG
AZURE_OPENAI_ENDPOINT=https://dev-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=dev_api_key
AZURE_OPENAI_DEPLOY_GPT4O=dev-gpt4o
CACHE_MAX_SIZE=536870912  # 512MB
```

#### Docker Compose
```yaml
# docker-compose.dev.yml
version: '3.8'
services:
  fastapi:
    build: ./server
    ports:
      - "8000:8000"
    environment:
      - DEBUG=true
    volumes:
      - ./server:/app
      - ./data:/app/data
    command: uvicorn main:app --reload --host 0.0.0.0

  streamlit:
    build: ./app
    ports:
      - "8501:8501"
    environment:
      - DEBUG=true
    volumes:
      - ./app:/app
```

### 2. ìŠ¤í…Œì´ì§• í™˜ê²½

#### í™˜ê²½ë³€ìˆ˜
```bash
# .env.staging
DEBUG=false
LOG_LEVEL=INFO
AZURE_OPENAI_ENDPOINT=https://staging-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=staging_api_key
AZURE_OPENAI_DEPLOY_GPT4O=staging-gpt4o
CACHE_MAX_SIZE=1073741824  # 1GB
```

### 3. í”„ë¡œë•ì…˜ í™˜ê²½

#### í™˜ê²½ë³€ìˆ˜
```bash
# .env.production
DEBUG=false
LOG_LEVEL=WARNING
AZURE_OPENAI_ENDPOINT=https://prod-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=prod_api_key
AZURE_OPENAI_DEPLOY_GPT4O=prod-gpt4o
CACHE_MAX_SIZE=2147483648  # 2GB
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### 1. ë¡œê¹… ì„¤ì •

#### êµ¬ì¡°í™”ëœ ë¡œê¹…
```python
# logging_config.py
import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }
        return json.dumps(log_entry)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/app.log'),
        logging.StreamHandler()
    ]
)
```

### 2. í—¬ìŠ¤ì²´í¬

#### í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
```python
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "1.0.0",
        "services": {
            "api": "healthy",
            "cache": await cache_manager.health_check(),
            "vector_store": await vector_store.health_check()
        }
    }
```

### 3. ë©”íŠ¸ë¦­ ìˆ˜ì§‘

#### Prometheus ë©”íŠ¸ë¦­
```python
from prometheus_client import Counter, Histogram, generate_latest

# ë©”íŠ¸ë¦­ ì •ì˜
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')

@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    duration = time.time() - start_time
    
    REQUEST_COUNT.labels(method=request.method, endpoint=request.url.path).inc()
    REQUEST_DURATION.observe(duration)
    
    return response

@app.get("/metrics")
async def metrics():
    return Response(generate_latest(), media_type="text/plain")
```

## ğŸ”’ ë³´ì•ˆ ì„¤ì •

### 1. SSL/TLS ì„¤ì •

#### Nginx SSL ì„¤ì •
```nginx
# nginx.conf
server {
    listen 443 ssl;
    server_name your-domain.com;
    
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    
    location / {
        proxy_pass http://streamlit:8501;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
    
    location /api/ {
        proxy_pass http://fastapi:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

### 2. ë°©í™”ë²½ ì„¤ì •

#### UFW ì„¤ì • (Ubuntu)
```bash
# ê¸°ë³¸ ì •ì±… ì„¤ì •
sudo ufw default deny incoming
sudo ufw default allow outgoing

# SSH í—ˆìš©
sudo ufw allow ssh

# ì›¹ ì„œë¹„ìŠ¤ í—ˆìš©
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw allow 8000/tcp
sudo ufw allow 8501/tcp

# ë°©í™”ë²½ í™œì„±í™”
sudo ufw enable
```

### 3. í™˜ê²½ë³€ìˆ˜ ë³´ì•ˆ

#### ì‹œí¬ë¦¿ ê´€ë¦¬
```bash
# Docker Secrets ì‚¬ìš©
echo "your-secret-value" | docker secret create azure_openai_key -

# Kubernetes Secrets
kubectl create secret generic azure-secrets \
  --from-literal=endpoint=$AZURE_OPENAI_ENDPOINT \
  --from-literal=api-key=$AZURE_OPENAI_API_KEY
```

## ğŸš€ ë°°í¬ ìë™í™”

### 1. GitHub Actions CI/CD

#### ì›Œí¬í”Œë¡œìš° ì˜ˆì‹œ
```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Build Docker images
      run: |
        docker build -t ai-kg-backend:${{ github.sha }} ./server
        docker build -t ai-kg-frontend:${{ github.sha }} ./app
    
    - name: Deploy to AWS
      run: |
        aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com
        docker tag ai-kg-backend:${{ github.sha }} ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com/ai-kg-backend:latest
        docker push ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com/ai-kg-backend:latest
    
    - name: Update ECS service
      run: |
        aws ecs update-service --cluster ai-kg-cluster --service ai-kg-service --force-new-deployment
```

### 2. ë°°í¬ ìŠ¤í¬ë¦½íŠ¸

#### ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì˜ˆì‹œ
```bash
#!/bin/bash
# deploy.sh

set -e

# í™˜ê²½ í™•ì¸
if [ -z "$ENVIRONMENT" ]; then
    echo "ENVIRONMENT ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš” (dev/staging/prod)"
    exit 1
fi

# ë°±ì—… ìƒì„±
echo "ë°±ì—… ìƒì„± ì¤‘..."
tar -czf backup-$(date +%Y%m%d-%H%M%S).tar.gz ./data

# ìƒˆ ë²„ì „ ë°°í¬
echo "ìƒˆ ë²„ì „ ë°°í¬ ì¤‘..."
docker-compose -f docker-compose.${ENVIRONMENT}.yml pull
docker-compose -f docker-compose.${ENVIRONMENT}.yml up -d

# í—¬ìŠ¤ì²´í¬
echo "í—¬ìŠ¤ì²´í¬ ì¤‘..."
for i in {1..30}; do
    if curl -f http://localhost:8000/health > /dev/null 2>&1; then
        echo "ë°°í¬ ì„±ê³µ!"
        exit 0
    fi
    sleep 2
done

echo "ë°°í¬ ì‹¤íŒ¨: í—¬ìŠ¤ì²´í¬ íƒ€ì„ì•„ì›ƒ"
exit 1
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### 1. ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­

#### ìµœì†Œ ìš”êµ¬ì‚¬í•­
- **CPU**: 2 vCPU
- **ë©”ëª¨ë¦¬**: 8GB RAM
- **ë””ìŠ¤í¬**: 50GB SSD
- **ë„¤íŠ¸ì›Œí¬**: 100Mbps

#### ê¶Œì¥ ìš”êµ¬ì‚¬í•­
- **CPU**: 4 vCPU
- **ë©”ëª¨ë¦¬**: 16GB RAM
- **ë””ìŠ¤í¬**: 100GB SSD
- **ë„¤íŠ¸ì›Œí¬**: 1Gbps

### 2. ìŠ¤ì¼€ì¼ë§ ì „ëµ

#### ìˆ˜í‰ ìŠ¤ì¼€ì¼ë§
```yaml
# docker-compose.scale.yml
services:
  fastapi:
    deploy:
      replicas: 3
    environment:
      - WORKER_PROCESSES=4
  
  streamlit:
    deploy:
      replicas: 2
```

#### ë¡œë“œ ë°¸ëŸ°ì‹±
```nginx
# nginx.conf
upstream fastapi_backend {
    least_conn;
    server fastapi1:8000;
    server fastapi2:8000;
    server fastapi3:8000;
}

server {
    location /api/ {
        proxy_pass http://fastapi_backend;
    }
}
```

## ğŸ› ï¸ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë°°í¬ ë¬¸ì œ

#### 1. í¬íŠ¸ ì¶©ëŒ
```bash
# ì‚¬ìš© ì¤‘ì¸ í¬íŠ¸ í™•ì¸
netstat -tulpn | grep :8000
lsof -i :8501

# í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
kill -9 <PID>
```

#### 2. ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
free -h
docker stats

# ë¶ˆí•„ìš”í•œ ì»¨í…Œì´ë„ˆ ì •ë¦¬
docker container prune
docker image prune
```

#### 3. ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±
```bash
# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸
df -h
du -sh ./data/*

# ë¡œê·¸ íŒŒì¼ ì •ë¦¬
find ./logs -name "*.log" -mtime +7 -delete
```

### ë¡œê·¸ ë¶„ì„

#### ë¡œê·¸ ëª¨ë‹ˆí„°ë§
```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸
docker-compose logs -f fastapi

# ì—ëŸ¬ ë¡œê·¸ í•„í„°ë§
docker-compose logs fastapi | grep ERROR

# íŠ¹ì • ì‹œê°„ëŒ€ ë¡œê·¸
docker-compose logs --since="2025-08-07T10:00:00" fastapi
```

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- **Docker ë¬¸ì„œ**: https://docs.docker.com/
- **Kubernetes ë¬¸ì„œ**: https://kubernetes.io/docs/
- **Terraform ë¬¸ì„œ**: https://www.terraform.io/docs/
- **Nginx ë¬¸ì„œ**: https://nginx.org/en/docs/
- **Prometheus ë¬¸ì„œ**: https://prometheus.io/docs/

---

*ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2025-08-07* 